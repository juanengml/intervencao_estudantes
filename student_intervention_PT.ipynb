{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Projeto 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "Sim, este é um problema de classificação,por que é esse tipo de problema se resolve pensando em \"quem\", quem são os alunos que precisão de intervenção é não \"quantos\", se fosse um problema de \"quantos\" alunos precisam de intervenção seria regressão visto que seram resultados discretos e não continuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Os dados dos estudantes foram lidos com êxito!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calcule o número de estudante\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = student_data.shape[1] - 1\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "\n",
    "n_passed = student_data[student_data['passed']=='yes'].shape[0]\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = student_data[student_data['passed']=='no'].shape[0]\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "passou = float(n_passed * 1.00)\n",
    "allstudantes = float(n_students * 1.00)\n",
    "\n",
    "grad_rate = ( passou / allstudantes ) * 100\n",
    "\n",
    "# Imprima os resultados\n",
    "print \"Número total de estudantes: {}\".format(n_students)\n",
    "print \"Número de atributos: {}\".format(n_features)\n",
    "print \"Número de estudantes aprovados: {}\".format(n_passed)\n",
    "print \"Número de estudantes reprovados: {}\".format(n_failed)\n",
    "print \"Taxa de graduação: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f58cbf390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f5fcfa5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotYes = student_data[student_data['passed']=='yes']['absences']\n",
    "plotYes.plot()\n",
    "plotNot = student_data[student_data['passed']=='no']['absences']\n",
    "plotNot.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extraia a coluna-alvo 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (_dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 296 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn import cross_validation\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300 # 75% dos dados\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_all,y_all,test_size=num_test,train_size = 0.75, random_state=42)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "0) *Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "\n",
    "**0) R: Tah, escolhi falar sobre Naive Bayes, Regressão Logistica eeeeeeeeeee chan chan chan chaaaann.... rsrsr Suport Vector MACHINE !!!!**\n",
    "\n",
    "1) Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "2) Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "3) Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "\n",
    "4) O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "Aplicação 1.1) Classificação de Spam fiz esse projeto nesse nanodegree gostei muito, da pra aplicar ele tambem para analise de sentimentos. \n",
    "\n",
    "Good) 2.1) Naive Bayes - Coisas Boas deste mod rsrsr, first -  não precisa de muitos dados para ter um excelente desempenho, visto que comparado a outros modelos como mais chatinhos como SVM que precisa de MILHÕÕÕÕÕÕÕÕES de dados rsrsr (bastante dados), fora que Naive Bayes pode operar com muitissimas classes, o que por consequencia tem menor tempo e treinamento PS: gosto dele vi sua aplicação há algum tempo nas aulas de estatistica rrsrsrsrsr.\n",
    "\n",
    "Bad) 3.1) Naive Bayes - Coisa bad sad neste mod Y_Y, ele não tem tanta precisão nos calculos, é indicado normalmente no final do rolê das analises, o que tambem é chato nele é pq tem representações  simples demais e não ajuda melhorar pq n tem esquema de ajustar os parametrozinho como tem em outros algoritmos. \n",
    "\n",
    "4.1) Naive Bayes Escolhi este algoritmo devido há quantidade de exemplos que existem na internet pra usar ele, é bem simples de implementar, simples de entender se vc ja viu estatistica alguma vez na faculdade é uma excelente escolha acredito. Vale ressaltar que a simplicidade do modelo ajuda na apresentação para os superiores da escola visto que ele é bastante simples de aplicar e apresentar dados trabalhados nele.\n",
    "\n",
    "## Regressão Logistica\n",
    "\n",
    "Aplicação 1.2)  real disso segundo o livro top que li o Data Smart do  autor Jhown W. Foreman ele aplica em campanhas de marketing, no excelente artigo da mackenzie eles falam tambem sobre a estrategia de marketing de fidelizar clientes usando o algoritmo de regress logistic. \n",
    "\n",
    "Good) 2.2) Regressão Logística,Coisas boas deste mode e que existem muitas manerias de regularizar o modelo para tolerar o tratamento de alguns erros e evitar os excessos de ajustos\n",
    "diferente do Bayes, não há nescessidade de preocupação para com recursos correlacionados, diferente de SVM, podemos sim facilmente entrar com novos dados por meio de metodos de gradiente descendente de forma online e facil de trabalhar, outro ponto legal e que no modulo da sklearn possui hipperparametros para ajuste que podem rapidamente fazer grids e validação cruzada, com isso os LR torna prababilidades excelentemente muito calibradas em vez de uma estimativa com maior probabilidade. \n",
    "\n",
    "Bad) 3.2) Regressão Logistica - bad things of this mod, bah, ele é linear e não consegue trabalhar com relações complexas e sugeneras, com isso outros algoritmos mais simples podem  ser  melhor que ele nesse ponto, ele requer que as observações sejam independente umas das outras e pretende prever com vase em variaveis independentes, se isso não existir ou não for devidademente identificado, os valores de predição poderam não ser encontrados.\n",
    "\n",
    "4.2) Regressão Logistica. Neste ponto sobre o consumo de recursos podem ser ligados a RL, ao contrario de NB pode sim lidar com esse problema visto que regularização e ajustes podem evitar treinos viciados devido ao conjunto de dados com bastantes recursos. \n",
    "\n",
    "## Suport Vector Machine\n",
    "\n",
    "Aplicação 1.3) Aplicação de detecção de genero usando reconheimento de imagem com coorelação, usado pelo pessoal da ufrj. \n",
    "\n",
    "Good) 2.3) Suporte Vector MACHINEEE !!! Good things of this module, tem excelente parâmetros de regularização para tolerar alguns erros e evitar o ajustes excessivos. Possui uns hackes de Kernel que permite que os users construir uma base de conhecimentos especializado sobre o problema através dos hacks do kernel, ele tabem fornece uma boa generalização fora da amostra, se os parâmetros C e gama forem apropriadamente ajustados, com isso SVM pode ser bastante robusto mesmo que a amostra de treno tenha alguns viés.\n",
    "            \n",
    "Bad) 3.3) Suport Vector Machine ! Coisa bad deste modulo, caro pra treinar por causa do tempo de treino, custo computacional mt mt high, precisa manjar das funções de kernel dele pra operar bem o algoritmo. \n",
    "\n",
    "4.3) Suporte Vector MACHINE !  \n",
    "Eu escolhi por que ele é bem robusto pra resolver o problema usando muitos recursos podem ser correlacionados e na regularização para evitar overfitting devido ao conjunto de dados com muitos recursos.\n",
    " \n",
    "\n",
    "### FONTES\n",
    "Naive Bayes\n",
    "\n",
    "https://web.stanford.edu/class/cs124/lec/naivebayes.pdf\n",
    "\n",
    "https://www.vooo.pro/insights/6-passos-faceis-para-aprender-o-algoritmo-naive-bayes-com-o-codigo-em-python/\n",
    "\n",
    "Regressão Logistica\n",
    "\n",
    "CAPITULO 6 - DATA SMART JHOWN W. FOREMAN.\n",
    "\n",
    "http://www.mackenzie.br/fileadmin/Pesquisa/pibic/publicacoes/2011/pdf/epro/karina_cavalcante.pdf\n",
    "\n",
    "Suport Vector MACHINE ! \n",
    "\n",
    "http://pee.ufrj.br/teses/textocompleto/2010021901.pdf\n",
    "http://www.semantix.com.br/10-algoritmos-de-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label=\"yes\")\n",
    "\n",
    "    \n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTreinando GaussianNB(priors=None)\n",
      "\n",
      "\n",
      "Treinando um GaussianNB com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0012 segundos\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8467.\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8029.\n",
      "\n",
      "\n",
      "Treinando um GaussianNB com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0013 segundos\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8406.\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7244.\n",
      "\n",
      "\n",
      "Treinando um GaussianNB com 296 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0014 segundos\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8067.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7634.\n",
      "\n",
      "\n",
      "Treinando um GaussianNB com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0011 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8406.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7244.\n",
      "\n",
      "\n",
      "Treinando um GaussianNB com 296 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0012 segundos\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8067.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7634.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tTreinando SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "\n",
      "Treinando um SVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0019 segundos\n",
      "As previsões foram feitas em 0.0012 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8777.\n",
      "As previsões foram feitas em 0.0011 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7746.\n",
      "\n",
      "\n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0047 segundos\n",
      "As previsões foram feitas em 0.0029 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8679.\n",
      "As previsões foram feitas em 0.0015 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7815.\n",
      "\n",
      "\n",
      "Treinando um SVC com 296 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0080 segundos\n",
      "As previsões foram feitas em 0.0063 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8750.\n",
      "As previsões foram feitas em 0.0021 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7785.\n",
      "\n",
      "\n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0039 segundos\n",
      "As previsões foram feitas em 0.0029 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8679.\n",
      "As previsões foram feitas em 0.0017 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7815.\n",
      "\n",
      "\n",
      "Treinando um SVC com 296 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0081 segundos\n",
      "As previsões foram feitas em 0.0061 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8750.\n",
      "As previsões foram feitas em 0.0021 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7785.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tTreinando LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Treinando um LogisticRegression com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0014 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8593.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7647.\n",
      "\n",
      "\n",
      "Treinando um LogisticRegression com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0025 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8562.\n",
      "As previsões foram feitas em 0.0002 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7914.\n",
      "\n",
      "\n",
      "Treinando um LogisticRegression com 296 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0028 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8481.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7883.\n",
      "\n",
      "\n",
      "Treinando um LogisticRegression com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0023 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8562.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7914.\n",
      "\n",
      "\n",
      "Treinando um LogisticRegression com 296 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0036 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8481.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7883.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "classificador_A = GaussianNB()\n",
    "classificador_B = SVC(random_state=0)\n",
    "classificador_C = LogisticRegression(random_state=0,n_jobs=-1)\n",
    "\n",
    "\n",
    "# TODO: Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "for classificador in [classificador_A, classificador_B, classificador_C]:\n",
    "    print \"\\tTreinando \" + str(classificador) + \"\\n\\n\"\n",
    "    for n_train in [100, 200, 300]:\n",
    "        train_predict(classificador, X_train[:n_train], y_train[:n_train], X_test, y_test)\n",
    "        print \"\\n\"\n",
    "    for n_train in [200]:\n",
    "        train_predict(classificador, X_train[:n_train], y_train[:n_train], X_test, y_test)\n",
    "        print \"\\n\"     \n",
    "    for n_train in [300]:\n",
    "        train_predict(classificador, X_train[:n_train], y_train[:n_train], X_test, y_test)\n",
    "        print \"\\n\"        \n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Resultados em tabelas\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 1 - **  GaussianNB\n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |      0,0015                |           0.0006                 |   0.7970                         |               0.7009       |\n",
    "| 200                                |   0.0029                   |              0.0007              |        0.8166                        |                0.7731      |\n",
    "| 300                                |         0.0016             |               0.0004             |    0.7981                          |               0.7521       |\n",
    "\n",
    "** Classificador 2 - **  SVC\n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |         0.0018             |         0.0013                  |  0.8466                            |                 0.7682     |\n",
    "| 200                                |  0.0051             |                    0.0017        |       0.8777                      |                 0.7568     |\n",
    "| 300                                |        0.0091              |               0.0026              |   0.8697                         |                 0.7448     |\n",
    "\n",
    "** Classificador 3 - **  LogisticRegression\n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |           0,0015           |          0.0003                   |     0.8784                       |              0.7463        |\n",
    "| 200                                |      0.0028                |                0.0004             |    0.8381                           |         0.7704             |\n",
    "| 300                                |     0.0029                 |               0.0004              |     0.8333                       |          0.7424            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** \n",
    "O que é Suporte Vector Machine ?\n",
    "SVM é uma tecnica de aprendizado de maquina supervisionado, que os resultados da aplicaçao da tecnica são comparaveis e muitas vezes superiores a algoritmos de RNA, com aplicação em diversas areas como analise de texto, imagens, e bioinformatica. Ela se torna interressante pelo fato de seu aprendizado ser baseado em aprindizado estatistico, visto que sua capacidade de prever corretamente a classe de dados do mesmo donimio em que o aprendizado ocorreu.\n",
    "\n",
    "Como funciona Estapas de treinamento do SVM ? \n",
    "Inicianmente ela mapea todos os dados em um espaço variavelmente dimensional para que os pontos dos dados possa ser categorizados, mesmo se os dados não forem linearmente separados,PS: com hacks de Kernel rola sim, após separar os dados serão transformados de modo que separados possam ser plotados como um hiperplano, dps disse podemos utilizar as novas caracteristicas dos novos dados para prever agrupamentos ao qual novo dados de entrada pertenceram.\n",
    "Como Validar o Modelo ? \n",
    "\n",
    "Como Aplicar o Modelo ? \n",
    "\n",
    "Comparando modelos creio que Suporte Vector Machine com um grau de acertividade maior na pontução do F1 visto que os demais visto que em Niveis de Pontuação de F1 o Scores se torna maior comparado com os modelos de Naive Bayes e LogisticRegression. Em Contra partida SVM demorou mais em tempo de treino e test comparado com os outros 2. Ou seja, SVM hoje !  SVM AMANHA ! SVM SEMPRE ! (SVM teve melhor desempenho, porem com um tempo de treino e test mais demorado que os demais) enfim conclui que os 3 são mt bons soq eu escolhi o SVM ** {>////<} **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "Pense em um quadro pontilhados com varios pontos separados por cores, verde, amarelo, azul e rosa. Visto que todos estão nos respectivo cantos do quadro, o modelo Suporte Vector Machine, ele divide os dados como um ninja cortando a tela em 4 grupos no caso do quadro, com isso ele classifica os dados nas fronteiras da tomade decisão, ele é muito conhecido por ser um classificador binario, porem se vc usar uns \"truques\" tipo hasquear usando Kernel, consegue pegar não apenas 2 tipos de classes porem todas as classes processando dados que seriam lineares e não lineares, podendo assim ajustar o modelo para melhor performace nas tomadas de decisão.HAHA ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapas \n",
    "\n",
    "- Uma (SVM) é um algoritmo de aprendizado de máquina supervisionado que pode ser empregado para propósitos de classificação e regressão. SVMs são mais comumente usados em problemas de classificação e, como tal, é nisso que vamos nos concentrar neste post. Os SVMs baseiam-se na ideia de encontrar um hiperplano que melhor divida um conjunto de dados em duas classes, como mostra a imagem abaixo.\n",
    "![1](svm0.png)\n",
    "---\n",
    "-  Os Vectores Suporte são os pontos de dados mais próximos do hiperplano, os pontos de um conjunto de dados que, se removidos, alterariam a posição do hiperplano divisor. Por causa disso, eles podem ser considerados os elementos críticos de um conjunto de dados. \n",
    "  O que é um hiperplano?\n",
    "  Como um exemplo simples, para uma tarefa de classificação com apenas dois recursos (como a imagem acima), você pode pensar em um hiperplano como uma linha que separa e classifica linearmente um conjunto de dados.\n",
    "\n",
    "  Intuitivamente, quanto mais longe do hiperplano nossos pontos de dados estiverem, mais confiantes estaremos de que foram classificados corretamente. Portanto, queremos que nossos pontos de dados estejam o mais longe possível do hiperplano, enquanto ainda estivermos do lado correto dele.\n",
    "  Então, quando novos dados de teste são adicionados, qualquer lado do hiperplano que ele for decidirá a classe que atribuímos a ele.\n",
    "  Como encontramos o hiperplano certo?Ou, em outras palavras, como separar melhor as duas classes nos dados?\n",
    "  A distância entre o hiperplano e o ponto de dados mais próximo de qualquer conjunto é conhecida como margem. O objetivo é escolher um hiperplano com a maior margem possível entre o hiperplano e qualquer ponto dentro do conjunto de treinamento, dando uma chance maior de novos dados serem classificados corretamente.\n",
    "![2](svm1.png)\n",
    "---\n",
    "- Mas o que acontece quando não há hiperplano claro?\n",
    " É aqui que pode ficar complicado. Os dados raramente são tão limpos quanto o nosso exemplo simples acima. Um conjunto de dados muitas vezes parece mais com as bolas confusas abaixo, que representam um conjunto de dados linearmente não separável.\n",
    "![3](svm2.png)\n",
    "---  \n",
    "- Para classificar um conjunto de dados como o acima, é necessário se afastar de uma visualização em 2D dos dados para uma visualização em 3D. Explicar isso é mais fácil com outro exemplo simplificado. Imagine que nossos dois conjuntos de bolas coloridas acima estão sentados em um lençol e este lençol é levantado de repente, lançando as bolas no ar. Enquanto as bolas estão no ar, você usa a folha para separá-las. Este \"levantamento\" das bolas representa o mapeamento dos dados em uma dimensão maior. Isso é conhecido como kernelling. Você pode ler mais sobre Kerneling\n",
    "![]\n",
    "--- \n",
    "\n",
    "![4](svm3.png)\n",
    "\n",
    "- Porque agora estamos em três dimensões, nosso hiperplano não pode mais ser uma linha. Agora deve ser um plano, como mostrado no exemplo acima. A ideia é que os dados continuem sendo mapeados em dimensões cada vez maiores até que um hiperplano possa ser formado para segregá-lo.\n",
    "![]\n",
    "--- \n",
    "\n",
    "###### Fontes: \n",
    "- svm para datasciences Juniors: https://69206c696b652074686973.blogspot.com.br/2018/04/suporte-vector-machine-para-datascience.html\n",
    "\n",
    "- svm for dummies: http://blog.aylien.com/support-vector-machines-for-dummies-a-simple/ \n",
    "\n",
    "- eli5: https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/\n",
    "\n",
    "- SVM WIKI Aprendis: http://aprendis.gim.med.up.pt/index.php/Support_Vector_Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo (_Tuning_)\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "classificador =  SVC(random_state=0)\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"yes\") \n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "\n",
    "grid_obj = GridSearchCV(classificador, parameters, scoring=f1_scorer)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj =  grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "classificador = grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As previsões foram feitas em 0.0038 segundos.\n",
      "O modelo calibrado tem F1 de 0.8552 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0014 segundos.\n",
      "O modelo calibrado tem F1 de 0.7761 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(classificador, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(classificador, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo estimado na fase de tunning ficou teve pontuação menor do que o utilizado nos ensaios anteriores, utilizando os parâmetros padrões.\n",
    "\n",
    "\n",
    "1. Antes do tunning F1 Score de treino dava 0.7970\n",
    "2. Dps do Tunning F1 Score de treino 0.8552"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
